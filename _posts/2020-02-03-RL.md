# \[RL\] [Fundamentals of Reinforcement Learning](https://www.coursera.org/learn/fundamentals-of-reinforcement-learning/home/welcome) [Week 3](https://www.coursera.org/learn/fundamentals-of-reinforcement-learning/home/week/3)

### 

## How are bellman equations useful?

It enables us to rewrite the value functions recursively and into systems of equations. This allows us to solve the equation without needing to consider all the future. You don’t need all the future values to compute the current value; you only need a prediction of the future value.

## What makes a policy an optimal policy?

When the policy’s values for all states are equal to or better than other policies’ values. In other words, an optimal policy is equal to or better than any policy. There is always an optimal policy but there may be multiple optimal policies.

## How are the bellman optimality equations useful?

It enable us to rewrite the equation without policy pi and rewrite it in terms of value functions.

## What is an optimal value function?

The value function under an optimal policy.

## How do I find the optimal policy given the optimal value functions?

Maximize the value function at each state. The question then is how to find the optimal value function.

Value function = Total reward of a state = immediate reward + discounted future value function.
